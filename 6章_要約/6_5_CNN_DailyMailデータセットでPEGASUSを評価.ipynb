{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdksIDfLuJ/WiB11t6HyPK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LASI_zZ7Yea"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.57.6 evaluate sacrebleu rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なもの\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
        "summaries = {}\n",
        "\n",
        "## NLTK パッケージ\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "## ベースライン\n",
        "def three_sentence_summary(text):\n",
        "  return \"\\n\".join(sent_tokenize(text)[:3])\n",
        "summaries[\"baseline\"] = three_sentence_summary(sample_text)\n",
        "\n",
        "## GPT-2 による結果\n",
        "from transformers import pipeline, set_seed\n",
        "set_seed(42)\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
        "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
        "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
        "summaries[\"gpt2\"] = \"\\n\".join(\n",
        "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))\n",
        "\n",
        "## T5 による結果\n",
        "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))\n",
        "\n",
        "## BART による結果\n",
        "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))\n",
        "\n",
        "## PEGASUS による結果\n",
        "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .\", \".\\n\")\n",
        "\n",
        "## ROUGE スコアメトリック\n",
        "import evaluate\n",
        "rouge_metric = evaluate.load('rouge')\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KTEZDHEM9fJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ベースラインの評価\n",
        "def evaluate_summaries_baseline(dataset, metric,\n",
        "                                column_text=\"article\",\n",
        "                                column_summary=\"highlights\"):\n",
        "  summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "  score = metric.compute(predictions=summaries,\n",
        "                         references=dataset[column_summary])\n",
        "  return score"
      ],
      "metadata": {
        "id": "GMLKnQvp-mzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプリングしたデータで評価\n",
        "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
        "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
        "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
      ],
      "metadata": {
        "id": "luSOM59p_Xwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "SmuK1wcqAQNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def chunks(list_of_elements, batch_size):\n",
        "  \"\"\"list_of_elements から連続したバッチサイズのチャンクを取得して返す\"\"\"\n",
        "  for i in range(0, len(list_of_elements), batch_size):\n",
        "    yield list_of_elements[i : i+batch_size]\n",
        "\n",
        "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
        "                               batch_size=16, device=device,\n",
        "                               column_text=\"article\",\n",
        "                               column_summary=\"highlights\"):\n",
        "  article_batches = list(chunks(dataset[column_text], batch_size))\n",
        "  target_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "  predictions = []\n",
        "  references = []\n",
        "  for article_batch, target_batch in tqdm(\n",
        "      zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "      inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
        "                         padding=\"max_length\", return_tensors=\"pt\")\n",
        "      summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                                 attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                                 length_penalty=0.8, num_beams=8, max_length=128)\n",
        "      decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                            clean_up_tokenization_spaces=True)\n",
        "                            for s in summaries]\n",
        "      decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "      predictions.extend(decoded_summaries)\n",
        "      references.extend(target_batch)\n",
        "\n",
        "  score = metric.compute(predictions=predictions, references=references)\n",
        "  return score"
      ],
      "metadata": {
        "id": "yaMGv9igAL7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルをロードして評価 (T4で約1時間)\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
        "                                   model, tokenizer, batch_size=8)\n",
        "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
      ],
      "metadata": {
        "id": "TA-u8m3iDoYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}