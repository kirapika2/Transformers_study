{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCbAAgyn/FmwLZIiLccV3d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# v5.0.0 では Jupyter でカスタムモデルをロードした際に AttributeError: module '__main__' has no attribute '__file__' が発生する\n",
        "# 関連 Issue: https://github.com/huggingface/transformers/issues/43645\n",
        "# 2026/02/05 時点では修正が反映されていないため、原因となったコードが入る前のバージョンに戻す\n",
        "!pip install transformers==4.52.4"
      ],
      "metadata": {
        "id": "Z5gN-RiiaSzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzjE1Qx2LFLM"
      },
      "outputs": [],
      "source": [
        "# トークン分類用カスタムモデル\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel\n",
        "\n",
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.num_labels = config.num_labels\n",
        "    # ボディをロード\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False) # [CLS]トークンによる表現抽出層の無効化\n",
        "    # トークン分類ヘッドの用意\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    # 重みのロードと初期化\n",
        "    self.init_weights()\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "              labels=None, **kwargs):\n",
        "    # ボディによりエンコーダの表現を取得\n",
        "    outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids, **kwargs)\n",
        "    # 分類器を適用\n",
        "    sequence_output = self.dropout(outputs[0]) # 最後の隠れ状態\n",
        "    logits = self.classifier(sequence_output)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    # モデルの出力オブジェクトとして返す\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits,\n",
        "                                 hidden_states=outputs.hidden_states,\n",
        "                                 attentions=outputs.attentions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 各固有表現のタグ\n",
        "## 固有表現のデータセット用意\n",
        "from collections import defaultdict\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
        "fracs = [0.629, 0.229, 0.084, 0.059]\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(langs,fracs):\n",
        "  ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
        "  for split in ds:\n",
        "    panx_ch[lang][split] = (\n",
        "        ds[split]\n",
        "        .shuffle(seed=0)\n",
        "        .select(range(int(frac*ds[split].num_rows)))\n",
        "    )\n",
        "\n",
        "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
        "\n",
        "## タグの取得\n",
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
      ],
      "metadata": {
        "id": "ZEzvOH-QPo1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定\n",
        "from transformers import AutoConfig\n",
        "xlmr_model_name = \"xlm-roberta-base\"\n",
        "\n",
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
        "                                         num_labels=tags.num_classes,\n",
        "                                         id2label=index2tag, label2id=tag2index)"
      ],
      "metadata": {
        "id": "ZmaD_EtMRy42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルロード\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "xlmr_model = (XLMRobertaForTokenClassification\n",
        "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
        "              .to(device))"
      ],
      "metadata": {
        "id": "72CJkQ25TGc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 簡単な系列のトークン化\n",
        "from transformers import AutoTokenizer\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n",
        "text = \"Jack Sparrow loves New York!\"\n",
        "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
      ],
      "metadata": {
        "id": "C1wLeoLQcHiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 各トークンの予測値\n",
        "outputs = xlmr_model(input_ids.to(device)).logits\n",
        "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
        "print(f\"Shape of outputs: {outputs.shape}\") # [1, 10, 7]"
      ],
      "metadata": {
        "id": "caS_jxsmduyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 各トークンの予測ラベル\n",
        "predictions = torch.argmax(outputs, dim=-1)\n",
        "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
      ],
      "metadata": {
        "id": "ooOpFTvafJtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ヘルパー関数\n",
        "def tag_text(text, tags, model, tokenizer):\n",
        "  # 特殊文字列も含んだトークンを取得\n",
        "  tokens = tokenizer(text).tokens()\n",
        "  # 系列をID化\n",
        "  input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
        "  # 7クラス分布の予測を取得\n",
        "  outputs = model(input_ids)[0]\n",
        "  # argmax で最も可能性の高いクラスを予測ラベルとする\n",
        "  predictions = torch.argmax(outputs, dim=2)\n",
        "  # DataFrame へ変換\n",
        "  preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "  return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
      ],
      "metadata": {
        "id": "RxLq2OsBf00E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}