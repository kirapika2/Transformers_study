{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxiCkuTwB9dI"
      },
      "outputs": [],
      "source": [
        "# 学習可能な事前学習済みモデルロード\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, DistilBertForSequenceClassification\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "num_labels = 6 # 感情数\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYH5kTQsDYim"
      },
      "outputs": [],
      "source": [
        "# トークナイザー\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFa6zJQ8G-Yf"
      },
      "outputs": [],
      "source": [
        "# 入力形式\n",
        "## emotionsデータ\n",
        "from datasets import load_dataset\n",
        "emotions = load_dataset(\"dair-ai/emotion\")\n",
        "\n",
        "## トークン化\n",
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
        "\n",
        "## 入力形式変更\n",
        "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]) # 各ラベルのテンソルがどういったものかが分かる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBEvaMV-hBNh"
      },
      "outputs": [],
      "source": [
        "# 性能評価関数\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  return {\"accuracy\": accuracy_score(labels, preds), \"f1\": f1_score(labels, preds, average=\"weighted\")}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface ログイン(write権限トークン)\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "XCSGUL733gTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnzVEyxqjlEj"
      },
      "outputs": [],
      "source": [
        "# 学習パラメータ\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "# logging_steps = len(emotions_encoded[\"train\"]) # 16000\n",
        "logging_steps = 250\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  eval_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  push_to_hub=True,\n",
        "                                  log_level=\"error\",\n",
        "                                  report_to='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSzgDp6klrDL"
      },
      "outputs": [],
      "source": [
        "# Trainer で学習\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotions_encoded[\"train\"],\n",
        "                  eval_dataset=emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 混同行列のプロット\n",
        "## 検証データセットの予測\n",
        "preds_output = trainer.predict(emotions_encoded[\"validation\"])\n",
        "print(preds_output.metrics) # accuracy と f1 を含むメトリクス\n",
        "\n",
        "## 正解ラベル\n",
        "import numpy as np\n",
        "y_valid = np.array(emotions_encoded[\"validation\"][\"label\"])\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "## 混同行列プロット関数\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "  plt.title(\"Normalized confusion matrix\")\n",
        "  plt.show()\n",
        "\n",
        "## ファインチューニングの混同行列\n",
        "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ],
      "metadata": {
        "id": "2Pk-teN1rxJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測ラベルと損失の取得\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_label(batch):\n",
        "  ## 入力テンソルをデバイスへ\n",
        "  inputs = {k:v.to(device) for k,v in batch.items()\n",
        "            if k in tokenizer.model_input_names}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(**inputs)\n",
        "    pred_label = torch.argmax(output.logits, axis=-1)\n",
        "    loss = cross_entropy(output.logits, batch[\"label\"].to(device),\n",
        "                          reduction=\"none\")\n",
        "  ## CPU で返す\n",
        "  return {\"loss\": loss.cpu().numpy(),\n",
        "          \"predicted_label\": pred_label.cpu().numpy()}"
      ],
      "metadata": {
        "id": "5c2ijbKU_wS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame 作成\n",
        "emotions_encoded[\"validation\"]  = emotions_encoded[\"validation\"].map(forward_pass_with_label, batched=True, batch_size=16)\n",
        "\n",
        "## ラベルを文字で表記\n",
        "def label_int2str(row):\n",
        "  return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "## DataFrame 化\n",
        "emotions_encoded.set_format(\"pandas\")\n",
        "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\n",
        "df_test = emotions_encoded[\"validation\"][:][cols]\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str) # 正解ラベル\n",
        "df_test[\"predicted_label\"] = (df_test[\"predicted_label\"].apply(label_int2str)) # 予測ラベル"
      ],
      "metadata": {
        "id": "t26Ditr6NAuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss の大きい順(10件)\n",
        "df_test.sort_values(\"loss\", ascending=False).head(10)"
      ],
      "metadata": {
        "id": "0x6Qc_6ZPhEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss の小さい順(10件)\n",
        "df_test.sort_values(\"loss\", ascending=True).head(10)"
      ],
      "metadata": {
        "id": "653v0erTQXI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのアップロード\n",
        "trainer.push_to_hub(commit_message=\"Training completed.\")"
      ],
      "metadata": {
        "id": "94TtonpMu0XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# アップしたモデルの利用\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"kirapika2/distilbert-base-uncased-finetuned-emotion\"\n",
        "classifier = pipeline(\"text-classification\", model=model_id)\n",
        "\n",
        "## テスト\n",
        "custom_tweet = \"I saw a movie today and it was really good.\" # 楽しそうな投稿\n",
        "preds = classifier(custom_tweet, return_all_scores=True)\n",
        "\n",
        "## 予測描画\n",
        "import pandas as pd\n",
        "preds_df = pd.DataFrame(preds[0])\n",
        "plt.bar(labels, 100*preds_df[\"score\"], color='C0')\n",
        "plt.title(f'\"{custom_tweet}\"')\n",
        "plt.ylabel(\"Class probability (%)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L58L-GNcRbAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow を使用するためバージョンを変更(新たなセッションで実行し、最初の3セルを次に実行)\n",
        "## バージョン確認\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "print(f\"transformers version: {transformers.__version__}\")\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "\n",
        "## trainsformers==4.49.0 に (http://reddit.com/r/cs50/comments/1mr1ef6/help_with_tensorflow_and_huggingface_transformers/)\n",
        "!pip uninstall -y transformers\n",
        "!pip install transformers==4.49.0"
      ],
      "metadata": {
        "id": "z3_r6y5fXUNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras を使ったファインチューニング\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "## モデルロード\n",
        "tf_model = (TFAutoModelForSequenceClassification\n",
        "            .from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "\n",
        "## データセットの TensorFlow 化\n",
        "tokenizer_columns = tokenizer.model_input_names\n",
        "batch_size = 64\n",
        "tf_train_dataset = emotions_encoded[\"train\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns, label_cols=[\"label\"], shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "tf_validation_dataset = emotions_encoded[\"validation\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns, label_cols=[\"label\"], shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "## 学習\n",
        "import tensorflow as tf\n",
        "tf_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy()\n",
        ")\n",
        "tf_model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=2)"
      ],
      "metadata": {
        "id": "FAUzJyf_VP8f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9lvChCwLynamfy0+PgcF1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}