{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfkc7Ta6OIrn9CdcpNDPhU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtKdRLgol9I4"
      },
      "outputs": [],
      "source": [
        "text = \"山路を登りながら、こう考えた。智に働けば角が立つ。情に棹させば流される。意地を通せば窮屈だ。とかくに人の世は住みにくい。\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#テキスト分類\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\")"
      ],
      "metadata": {
        "id": "fHOqGwn0nnnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "outputs = classifier(text) # dict のリスト\n",
        "pd.DataFrame(outputs)"
      ],
      "metadata": {
        "id": "niDqd2sgn6ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#固有表現認識\n",
        "\n",
        "from transformers import BertForTokenClassification, BertTokenizer\n",
        "\n",
        "## 日本語 BERT モデル\n",
        "model_name = \"cl-tohoku/bert-base-japanese\"\n",
        "ja_model = BertForTokenClassification.from_pretrained(model_name)\n",
        "ja_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "## NER 用パイプライン\n",
        "ner_pipeline = pipeline(\"ner\", model=ja_model, tokenizer=ja_tokenizer)\n",
        "\n",
        "## ラベルは微妙だが、トークンごとに判定されてそうなことが分かる\n",
        "ner_results = ner_pipeline(text)\n",
        "pd.DataFrame(ner_results)"
      ],
      "metadata": {
        "id": "GmzpEcfrooKC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#質疑応答\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "## 日本語 QA モデル( https://huggingface.co/Mizuiro-sakura/deberta-v2-base-japanese-finetuned-QA より)\n",
        "tokenizer = AutoTokenizer.from_pretrained('ku-nlp/deberta-v2-base-japanese')\n",
        "model=AutoModelForQuestionAnswering.from_pretrained('Mizuiro-sakura/deberta-v2-base-japanese-finetuned-QAe')\n",
        "\n",
        "question = \"意地を通すと？\"\n",
        "\n",
        "## 窮屈が抜き出せない\n",
        "input_ids=tokenizer.encode(question,text) # tokenizerで形態素解析しつつコードに変換する\n",
        "output= model(torch.tensor([input_ids])) # 学習済みモデルを用いて解析\n",
        "prediction = tokenizer.decode(input_ids[torch.argmax(output.start_logits): torch.argmax(output.end_logits)]) # 答えに該当する部分を抜き取る\n",
        "print(prediction)\n",
        "\n",
        "## 全文が出力されてしまう\n",
        "# from transformers import BertForQuestionAnswering\n",
        "# ja_qamodel = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "# reader = pipeline(task=\"question-answering\", model=ja_qamodel, tokenizer=ja_tokenizer)\n",
        "# outputs = reader(question=question, context=text)\n",
        "# pd.DataFrame([outputs])"
      ],
      "metadata": {
        "id": "vyaoGYMYzvt-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#要約\n",
        "\n",
        "## hugging face で良さげな日本語モデルが見つけられなかった\n",
        "summarizer = pipeline(\"summarization\")\n",
        "outputs = summarizer(text, max_length=45, min_length=10, do_sample=False)\n",
        "print(outputs[0]['summary_text'])"
      ],
      "metadata": {
        "id": "owRAq61c2Eap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#翻訳\n",
        "\n",
        "## 日本語 → 英語\n",
        "translator = pipeline(\"translation_ja_to_en\", model=\"Helsinki-NLP/opus-mt-ja-en\")\n",
        "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=10)\n",
        "print(outputs[0]['translation_text'])"
      ],
      "metadata": {
        "id": "S5D79ORu3QS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#生成\n",
        "\n",
        "## 日本語生成モデル( https://huggingface.co/ku-nlp/gpt2-small-japanese-char より)\n",
        "generator = pipeline(\"text-generation\", model='ku-nlp/gpt2-small-japanese-char')\n",
        "response = \"そういって\"\n",
        "prompt = text + \"\\n\" + response\n",
        "outputs = generator(prompt, max_length=200)\n",
        "print(outputs[0]['generated_text'])"
      ],
      "metadata": {
        "id": "F0cGCDYz6TcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}